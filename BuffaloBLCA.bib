
@article{collins_estimation_2014,
	title = {Estimation of diagnostic test accuracy without full verification: a review of latent class methods},
	volume = {33},
	copyright = {Published 2014. This article is a U.S. Government work and is in the public domain          in the USA.},
	issn = {1097-0258},
	shorttitle = {Estimation of diagnostic test accuracy without full verification},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6218},
	doi = {10.1002/sim.6218},
	abstract = {The performance of a diagnostic test is best evaluated against a reference test that is without error. For many diseases, this is not possible, and an imperfect reference test must be used. However, diagnostic accuracy estimates may be biased if inaccurately verified status is used as the truth. Statistical models have been developed to handle this situation by treating disease as a latent variable. In this paper, we conduct a systematized review of statistical methods using latent class models for estimating test accuracy and disease prevalence in the absence of complete verification. Published 2014. This article is a U.S. Government work and is in the public domain in the USA.},
	language = {en},
	number = {24},
	urldate = {2018-05-02},
	journal = {Statistics in Medicine},
	author = {Collins, John and Huynh, Minh},
	month = oct,
	year = {2014},
	keywords = {diagnostic testing, latent class model, no gold standard, review, sensitivity, specificity},
	pages = {4141--4169},
	file = {Full Text PDF:/Users/ajkc2/Zotero/storage/SQ85KIZE/Collins and Huynh - 2014 - Estimation of diagnostic test accuracy without ful.pdf:application/pdf;Snapshot:/Users/ajkc2/Zotero/storage/X9R6ZWJJ/sim.html:text/html},
}

@book{gelman_bayesian_2014,
	edition = {Third Edition},
	title = {Bayesian {Data} {Analysis}},
	publisher = {Chapman \& Hall},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, A. and Rubin, D B.},
	year = {2014},
}

@article{dendukuri_modeling_2009,
	title = {Modeling conditional dependence between diagnostic tests: a multiple latent variable model.},
	volume = {28},
	issn = {0277-6715},
	shorttitle = {Modeling conditional dependence between diagnostic tests},
	url = {http://europepmc.org/abstract/med/19067379},
	doi = {10.1002/sim.3470},
	abstract = {Abstract: Applications of latent class analysis in diagnostic test studies have assumed that all tests are measuring a common binary latent variable, the...},
	language = {eng},
	number = {3},
	urldate = {2018-07-05},
	journal = {Statistics in medicine},
	author = {Dendukuri, N. and Hadgu, A. and Wang, L.},
	month = feb,
	year = {2009},
	pmid = {19067379},
	pages = {441--461},
	file = {Snapshot:/Users/ajkc2/Zotero/storage/HN9UHD65/19067379.html:text/html},
}

@article{hui_estimating_1980,
	title = {Estimating the {Error} {Rates} of {Diagnostic} {Tests}},
	volume = {36},
	issn = {0006-341X},
	url = {http://www.jstor.org/stable/2530508},
	doi = {10.2307/2530508},
	abstract = {It is often required to evaluate the accuracy of a new diagnostic test against a standard test with unknown error rates. If the two tests are applied simultaneously to the same individuals from two populations with different disease prevalences, then assuming conditional independence of the errors of the two tests, the error rates of both tests and the true prevalences in both populations can be estimated by a maximum likelihood procedure. Generalizations to several tests applied in several populations are also possible.},
	number = {1},
	urldate = {2018-07-09},
	journal = {Biometrics},
	author = {Hui, S. L. and Walter, S. D.},
	year = {1980},
	pages = {167--171},
}

@article{carpenter_stan_2017,
	title = {Stan: {A} {Probabilistic} {Programming} {Language}},
	volume = {76},
	copyright = {Copyright (c) 2017 Bob Carpenter, Andrew Gelman, Matthew D. Hoffman, Daniel Lee, Ben Goodrich, Michael Betancourt, Marcus Brubaker, Jiqiang Guo, Peter Li, Allen Riddell},
	issn = {1548-7660},
	shorttitle = {Stan},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v076i01},
	doi = {10.18637/jss.v076.i01},
	language = {en},
	number = {1},
	urldate = {2020-04-21},
	journal = {Journal of Statistical Software},
	author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
	month = jan,
	year = {2017},
	note = {Number: 1},
	keywords = {Bayesian inference, algorithmic differentiation, probabilistic programming, Stan},
	pages = {1--32},
	file = {Full Text:/Users/ajkc2/Zotero/storage/T5TSQX3T/Carpenter et al. - 2017 - Stan A Probabilistic Programming Language.pdf:application/pdf;Snapshot:/Users/ajkc2/Zotero/storage/6FYK3CDM/v076i01.html:text/html},
}

@article{irwin_lognormal_nodate,
	title = {Lognormal {Lorenz} and normal receiver operating characteristic curves as mirror images},
	volume = {2},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.140280},
	doi = {10.1098/rsos.140280},
	abstract = {The Lorenz curve for assessing economic inequality depicts the relation between two cumulative distribution functions (CDFs), one for the distribution of incomes or wealth and the other for their first-moment distribution. By contrast, the receiver operating characteristic (ROC) curve for evaluating diagnostic systems depicts the relation between the complements of two CDFs, one for the distribution noise and the other for the distribution of signal plus noise. We demonstrate that the lognormal model of the Lorenz curve, which is often adopted to model the distribution of income and wealth, is a mirror image of the equal-variance normal model of the ROC curve, which is a fundamental model for evaluating diagnostic systems. The relationship between these two models extends the potential application of each. For example, the lognormal Lorenz curve can be used to evaluate diagnostic systems derived from equal-variance normal distributions.},
	number = {2},
	urldate = {2020-09-28},
	journal = {Royal Society Open Science},
	author = {Irwin, R. John and Hautus, Michael J.},
	note = {Publisher: Royal Society},
	pages = {140280},
	file = {Full Text PDF:/Users/ajkc2/Zotero/storage/UVYMEAD7/Irwin and Hautus - Lognormal Lorenz and normal receiver operating cha.pdf:application/pdf;Snapshot:/Users/ajkc2/Zotero/storage/QTFPR3HG/rsos.html:text/html},
}

@article{vehtari_practical_2017,
	title = {Practical {Bayesian} model evaluation using leave-one-out cross-validation and {WAIC}},
	volume = {27},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-016-9696-4},
	doi = {10.1007/s11222-016-9696-4},
	abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
	language = {en},
	number = {5},
	urldate = {2023-10-10},
	journal = {Statistics and Computing},
	author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
	month = sep,
	year = {2017},
	keywords = {Bayesian computation, K-fold cross-validation, Leave-one-out cross-validation (LOO), Pareto smoothed importance sampling (PSIS), Stan, Widely applicable information criterion (WAIC)},
	pages = {1413--1432},
	file = {Full Text PDF:/Users/ajkc2/Zotero/storage/GTNUWRDS/Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf:application/pdf},
}
